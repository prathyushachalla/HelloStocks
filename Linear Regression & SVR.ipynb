{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import numpy as np \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      ticker       date   adj_close\n",
       "None                              \n",
       "0       WMT 2018-03-15   87.510000\n",
       "1       WMT 2018-03-14   87.670000\n",
       "2       WMT 2018-03-13   88.300000\n",
       "3       WMT 2018-03-12   88.070000\n",
       "4       WMT 2018-03-09   88.720000\n",
       "5       WMT 2018-03-08   87.920000\n",
       "6       WMT 2018-03-07   87.740000\n",
       "7       WMT 2018-03-06   89.060000\n",
       "8       WMT 2018-03-05   89.980000\n",
       "9       WMT 2018-03-02   88.770000\n",
       "10      WMT 2018-03-01   89.080000\n",
       "11      WMT 2018-02-28   90.010000\n",
       "12      WMT 2018-02-27   91.520000\n",
       "13      WMT 2018-02-26   93.120000\n",
       "14      WMT 2018-02-23   92.890000\n",
       "15      WMT 2018-02-22   92.770000\n",
       "16      WMT 2018-02-21   91.520000\n",
       "17      WMT 2018-02-20   94.110000\n",
       "18      WMT 2018-02-16  104.780000\n",
       "19      WMT 2018-02-15  103.230000\n",
       "20      WMT 2018-02-14  101.700000\n",
       "21      WMT 2018-02-13  100.980000\n",
       "22      WMT 2018-02-12   99.550000\n",
       "23      WMT 2018-02-09   99.370000\n",
       "24      WMT 2018-02-08  100.020000\n",
       "25      WMT 2018-02-07  102.850000\n",
       "26      WMT 2018-02-06  100.900000\n",
       "27      WMT 2018-02-05  100.090000\n",
       "28      WMT 2018-02-02  104.480000\n",
       "29      WMT 2018-02-01  105.520000\n",
       "...     ...        ...         ...\n",
       "5960   AAPL 2012-04-26   78.097920\n",
       "5961   AAPL 2012-04-25   78.393502\n",
       "5962   AAPL 2012-04-24   72.003789\n",
       "5963   AAPL 2012-04-23   73.471418\n",
       "5964   AAPL 2012-04-20   73.635916\n",
       "5965   AAPL 2012-04-19   75.494228\n",
       "5966   AAPL 2012-04-18   78.180169\n",
       "5967   AAPL 2012-04-17   78.354948\n",
       "5968   AAPL 2012-04-16   74.554791\n",
       "5969   AAPL 2012-04-13   77.780490\n",
       "5970   AAPL 2012-04-12   80.034625\n",
       "5971   AAPL 2012-04-11   80.475428\n",
       "5972   AAPL 2012-04-10   80.763299\n",
       "5973   AAPL 2012-04-09   81.764423\n",
       "5974   AAPL 2012-04-05   81.436712\n",
       "5975   AAPL 2012-04-04   80.232536\n",
       "5976   AAPL 2012-04-03   80.876391\n",
       "5977   AAPL 2012-04-02   79.502577\n",
       "5978   AAPL 2012-03-30   77.050531\n",
       "5979   AAPL 2012-03-29   78.375510\n",
       "5980   AAPL 2012-03-28   79.372778\n",
       "5981   AAPL 2012-03-27   78.969244\n",
       "5982   AAPL 2012-03-26   78.005390\n",
       "5983   AAPL 2012-03-23   76.600733\n",
       "5984   AAPL 2012-03-22   77.023543\n",
       "5985   AAPL 2012-03-21   77.429647\n",
       "5986   AAPL 2012-03-20   77.874306\n",
       "5987   AAPL 2012-03-19   77.249728\n",
       "5988   AAPL 2012-03-16   75.253906\n",
       "5989   AAPL 2012-03-15   75.252621\n",
       "\n",
       "[5990 rows x 3 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://medium.com/@randerson112358/predict-stock-prices-using-python-machine-learning-53aa024da20a\n",
    "# Get the stock data\n",
    "\n",
    "quandl.ApiConfig.api_key = 'qKYyca8_q3vn5ws7FpwZ'\n",
    "\n",
    "#df = quandl.get(\"WIKI/FB\", trim_start = \"2012-03-15\", trim_end =\"2018-03-15\")\n",
    "\n",
    "# Take a look at the data\n",
    "#df.head()\n",
    "\n",
    "df = quandl.get_table('WIKI/PRICES', ticker = ['AAPL', 'MSFT', 'WMT',\"FB\"], \n",
    "                        qopts = { 'columns': ['ticker', 'date', 'adj_close'] }, \n",
    "                        date = { 'gte': '2012-03-15', 'lte': '2018-03-15' }, \n",
    "                        paginate=True)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj. Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-05-18</th>\n",
       "      <td>38.2318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-21</th>\n",
       "      <td>34.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-22</th>\n",
       "      <td>31.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-23</th>\n",
       "      <td>32.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-24</th>\n",
       "      <td>33.0300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj. Close\n",
       "Date                  \n",
       "2012-05-18     38.2318\n",
       "2012-05-21     34.0300\n",
       "2012-05-22     31.0000\n",
       "2012-05-23     32.0000\n",
       "2012-05-24     33.0300"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Adjusted Close Price \n",
    "df = df[['Adj. Close']] \n",
    "# Take a look at the new data \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-04</th>\n",
       "      <td>171.4700</td>\n",
       "      <td>176.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-05</th>\n",
       "      <td>172.8300</td>\n",
       "      <td>180.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-06</th>\n",
       "      <td>176.0600</td>\n",
       "      <td>179.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-07</th>\n",
       "      <td>180.1400</td>\n",
       "      <td>183.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-08</th>\n",
       "      <td>179.0000</td>\n",
       "      <td>182.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-11</th>\n",
       "      <td>179.0400</td>\n",
       "      <td>185.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-12</th>\n",
       "      <td>176.9600</td>\n",
       "      <td>184.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-13</th>\n",
       "      <td>178.3000</td>\n",
       "      <td>181.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-14</th>\n",
       "      <td>178.3900</td>\n",
       "      <td>184.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-15</th>\n",
       "      <td>180.1800</td>\n",
       "      <td>183.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-18</th>\n",
       "      <td>180.8200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-19</th>\n",
       "      <td>179.5100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-20</th>\n",
       "      <td>177.8900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-21</th>\n",
       "      <td>177.4500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-22</th>\n",
       "      <td>177.2000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-26</th>\n",
       "      <td>175.9900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-27</th>\n",
       "      <td>177.6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>177.9200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>176.4600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>181.4200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>184.6700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>184.3300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>186.8500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>188.2800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>187.8700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10</th>\n",
       "      <td>187.8400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-11</th>\n",
       "      <td>187.7700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-12</th>\n",
       "      <td>179.3700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-16</th>\n",
       "      <td>178.3900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-17</th>\n",
       "      <td>177.6000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>193.0900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>190.2800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>182.6500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>185.3100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>180.1800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-08</th>\n",
       "      <td>171.5499</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-09</th>\n",
       "      <td>175.9800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-12</th>\n",
       "      <td>176.4100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-13</th>\n",
       "      <td>173.1500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-14</th>\n",
       "      <td>179.5200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-15</th>\n",
       "      <td>179.9600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-16</th>\n",
       "      <td>177.3600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-20</th>\n",
       "      <td>176.0100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-21</th>\n",
       "      <td>177.9100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-22</th>\n",
       "      <td>178.9900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-23</th>\n",
       "      <td>183.2900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-26</th>\n",
       "      <td>184.9300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-27</th>\n",
       "      <td>181.4600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-28</th>\n",
       "      <td>178.3200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>175.9400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-02</th>\n",
       "      <td>176.6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-05</th>\n",
       "      <td>180.4000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-06</th>\n",
       "      <td>179.7800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-07</th>\n",
       "      <td>183.7100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-08</th>\n",
       "      <td>182.3400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-09</th>\n",
       "      <td>185.2300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-12</th>\n",
       "      <td>184.7600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-13</th>\n",
       "      <td>181.8800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-14</th>\n",
       "      <td>184.1900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-15</th>\n",
       "      <td>183.8600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj. Close  Prediction\n",
       "Date                              \n",
       "2017-12-04    171.4700      176.62\n",
       "2017-12-05    172.8300      180.40\n",
       "2017-12-06    176.0600      179.78\n",
       "2017-12-07    180.1400      183.71\n",
       "2017-12-08    179.0000      182.34\n",
       "2017-12-11    179.0400      185.23\n",
       "2017-12-12    176.9600      184.76\n",
       "2017-12-13    178.3000      181.88\n",
       "2017-12-14    178.3900      184.19\n",
       "2017-12-15    180.1800      183.86\n",
       "2017-12-18    180.8200         NaN\n",
       "2017-12-19    179.5100         NaN\n",
       "2017-12-20    177.8900         NaN\n",
       "2017-12-21    177.4500         NaN\n",
       "2017-12-22    177.2000         NaN\n",
       "2017-12-26    175.9900         NaN\n",
       "2017-12-27    177.6200         NaN\n",
       "2017-12-28    177.9200         NaN\n",
       "2017-12-29    176.4600         NaN\n",
       "2018-01-02    181.4200         NaN\n",
       "2018-01-03    184.6700         NaN\n",
       "2018-01-04    184.3300         NaN\n",
       "2018-01-05    186.8500         NaN\n",
       "2018-01-08    188.2800         NaN\n",
       "2018-01-09    187.8700         NaN\n",
       "2018-01-10    187.8400         NaN\n",
       "2018-01-11    187.7700         NaN\n",
       "2018-01-12    179.3700         NaN\n",
       "2018-01-16    178.3900         NaN\n",
       "2018-01-17    177.6000         NaN\n",
       "...                ...         ...\n",
       "2018-02-01    193.0900         NaN\n",
       "2018-02-02    190.2800         NaN\n",
       "2018-02-05    182.6500         NaN\n",
       "2018-02-06    185.3100         NaN\n",
       "2018-02-07    180.1800         NaN\n",
       "2018-02-08    171.5499         NaN\n",
       "2018-02-09    175.9800         NaN\n",
       "2018-02-12    176.4100         NaN\n",
       "2018-02-13    173.1500         NaN\n",
       "2018-02-14    179.5200         NaN\n",
       "2018-02-15    179.9600         NaN\n",
       "2018-02-16    177.3600         NaN\n",
       "2018-02-20    176.0100         NaN\n",
       "2018-02-21    177.9100         NaN\n",
       "2018-02-22    178.9900         NaN\n",
       "2018-02-23    183.2900         NaN\n",
       "2018-02-26    184.9300         NaN\n",
       "2018-02-27    181.4600         NaN\n",
       "2018-02-28    178.3200         NaN\n",
       "2018-03-01    175.9400         NaN\n",
       "2018-03-02    176.6200         NaN\n",
       "2018-03-05    180.4000         NaN\n",
       "2018-03-06    179.7800         NaN\n",
       "2018-03-07    183.7100         NaN\n",
       "2018-03-08    182.3400         NaN\n",
       "2018-03-09    185.2300         NaN\n",
       "2018-03-12    184.7600         NaN\n",
       "2018-03-13    181.8800         NaN\n",
       "2018-03-14    184.1900         NaN\n",
       "2018-03-15    183.8600         NaN\n",
       "\n",
       "[70 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A variable for predicting 'n' days out into the future\n",
    "forecast_out = 60\n",
    "#'n=30' days\n",
    "#Create another column (the target ) shifted 'n' units up\n",
    "df['Prediction'] = df[['Adj. Close']].shift(-forecast_out)\n",
    "#print the 12)\n",
    "df.tail(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 38.2318]\n",
      " [ 34.03  ]\n",
      " [ 31.    ]\n",
      " ...\n",
      " [178.3   ]\n",
      " [178.39  ]\n",
      " [180.18  ]]\n"
     ]
    }
   ],
   "source": [
    "### Create the independent data set (X)  #######\n",
    "# Convert the dataframe to a numpy array\n",
    "X = np.array(df.drop(['Prediction'],1))\n",
    "\n",
    "#Remove the last 'n' rows\n",
    "X = X[:-forecast_out]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20.38  21.2   19.87 ... 181.88 184.19 183.86]\n"
     ]
    }
   ],
   "source": [
    "### Create the dependent data set (y)  #####\n",
    "# Convert the dataframe to a numpy array \n",
    "y = np.array(df['Prediction'])\n",
    "# Get all of the y values except the last 'n' rows\n",
    "y = y[:-forecast_out]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 80% training and 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1000.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.1,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the Support Vector Machine (Regressor) \n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1) \n",
    "svr_rbf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm confidence:  0.9792415647324464\n"
     ]
    }
   ],
   "source": [
    "# Testing Model: Score returns the coefficient of determination R^2 of the prediction. \n",
    "# The best possible score is 1.0\n",
    "svm_confidence = svr_rbf.score(x_test, y_test)\n",
    "print(\"svm confidence: \", svm_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the Linear Regression  Model\n",
    "lr = LinearRegression()\n",
    "# Train the model\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr confidence:  0.9733333610682646\n"
     ]
    }
   ],
   "source": [
    "# Testing Model: Score returns the coefficient of determination R^2 of the prediction. \n",
    "# The best possible score is 1.0\n",
    "lr_confidence = lr.score(x_test, y_test)\n",
    "print(\"lr confidence: \", lr_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[180.82  ]\n",
      " [179.51  ]\n",
      " [177.89  ]\n",
      " [177.45  ]\n",
      " [177.2   ]\n",
      " [175.99  ]\n",
      " [177.62  ]\n",
      " [177.92  ]\n",
      " [176.46  ]\n",
      " [181.42  ]\n",
      " [184.67  ]\n",
      " [184.33  ]\n",
      " [186.85  ]\n",
      " [188.28  ]\n",
      " [187.87  ]\n",
      " [187.84  ]\n",
      " [187.77  ]\n",
      " [179.37  ]\n",
      " [178.39  ]\n",
      " [177.6   ]\n",
      " [179.8   ]\n",
      " [181.29  ]\n",
      " [185.37  ]\n",
      " [189.35  ]\n",
      " [186.55  ]\n",
      " [187.48  ]\n",
      " [190.    ]\n",
      " [185.98  ]\n",
      " [187.12  ]\n",
      " [186.89  ]\n",
      " [193.09  ]\n",
      " [190.28  ]\n",
      " [182.65  ]\n",
      " [185.31  ]\n",
      " [180.18  ]\n",
      " [171.5499]\n",
      " [175.98  ]\n",
      " [176.41  ]\n",
      " [173.15  ]\n",
      " [179.52  ]\n",
      " [179.96  ]\n",
      " [177.36  ]\n",
      " [176.01  ]\n",
      " [177.91  ]\n",
      " [178.99  ]\n",
      " [183.29  ]\n",
      " [184.93  ]\n",
      " [181.46  ]\n",
      " [178.32  ]\n",
      " [175.94  ]\n",
      " [176.62  ]\n",
      " [180.4   ]\n",
      " [179.78  ]\n",
      " [183.71  ]\n",
      " [182.34  ]\n",
      " [185.23  ]\n",
      " [184.76  ]\n",
      " [181.88  ]\n",
      " [184.19  ]\n",
      " [183.86  ]]\n"
     ]
    }
   ],
   "source": [
    "# Set x_forecast equal to the last 30 rows of the original data set from Adj. Close column\n",
    "x_forecast = np.array(df.drop(['Prediction'],1))[-forecast_out:]\n",
    "print(x_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[190.60849659 189.25718805 187.58610421 187.13222959 186.87434628\n",
      " 185.62619106 187.30759024 187.61705021 186.11101168 191.22741653\n",
      " 194.57989955 194.22917825 196.828642   198.30373453 197.8808059\n",
      " 197.84985991 197.77765258 189.1127734  188.10187083 187.28695957\n",
      " 189.55633269 191.09331721 195.30197281 199.40747509 196.51918203\n",
      " 197.47850794 200.0779717  195.93120809 197.10715598 196.86990333\n",
      " 203.26540939 200.366801   192.49620241 195.24008082 189.94831532\n",
      " 181.04608034 185.61587573 186.05943502 182.69663667 189.26750338\n",
      " 189.72137801 187.03939159 185.64682173 187.60673487 188.72079077\n",
      " 193.15638368 194.84809819 191.26867786 188.0296635  185.5746144\n",
      " 186.276057   190.17525263 189.53570203 193.58962764 192.17642711\n",
      " 195.15755816 194.67273754 191.70192182 194.0847636  193.74435763]\n"
     ]
    }
   ],
   "source": [
    "# Print linear regression model predictions for the next '30' days\n",
    "lr_prediction = lr.predict(x_forecast)\n",
    "print(lr_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180.39738039 184.04275158 178.17758101 178.0866333  178.38854766\n",
      " 179.63860772 178.01076547 178.22009652 179.56415413 177.02962797\n",
      " 188.34781314 190.34489775 143.70265737 119.51425244 124.64979712\n",
      " 125.0825016  126.12318055 183.68062653 179.50309201 178.01304347\n",
      " 184.33985287 177.62397875 178.1972807  111.84329131 150.72043122\n",
      " 130.8993495  109.88354716 164.64094084 137.84072494 142.80330365\n",
      " 108.37451136 109.39869007 179.67753092 179.34358899 183.68503592\n",
      " 180.87554535 179.63119023 179.60960958 179.43860142 184.06361263\n",
      " 184.21041381 178.17331814 179.65231847 178.20537689 182.19470014\n",
      " 185.7181578  185.46618853 176.87162958 179.24457515 179.5978108\n",
      " 179.36983177 182.79321516 184.3409313  189.11302311 177.50629518\n",
      " 180.80186691 187.48020941 176.1155072  190.58422762 189.91523854]\n"
     ]
    }
   ],
   "source": [
    "# Print support vector regressor model predictions for the next '30' days\n",
    "svm_prediction = svr_rbf.predict(x_forecast)\n",
    "print(svm_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
